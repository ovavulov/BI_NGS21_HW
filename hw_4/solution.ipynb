{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ данных NGS. Домашнее задание № 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнил: Олег Вавулов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "sys.path.insert(0, os.getcwd())\n",
    "import functions as f\n",
    "import pysam\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные храним вне проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(f.get_prev_path(cwd, 2), \"data\", \"hw_4\")\n",
    "bin_path = os.path.join(f.get_prev_path(cwd, 2), \"bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"original\"):\n",
    "    os.mkdir(\"original\")\n",
    "if not os.path.exists(\"trimmomatic\"):\n",
    "    os.mkdir(\"trimmomatic\")\n",
    "if not os.path.exists(\"bayeshammer\"):\n",
    "    os.mkdir(\"bayeshammer\")\n",
    "if not os.path.exists(os.path.join(data_path, \"trimmomatic\")):\n",
    "    os.mkdir(os.path.join(data_path, \"trimmomatic\"))\n",
    "if not os.path.exists(os.path.join(data_path, \"bayeshammer\")):\n",
    "    os.mkdir(os.path.join(data_path, \"bayeshammer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference genome length: 10000\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, \"MG1655-K12.first10K.fasta\")) as f:\n",
    "    reference = f.read()\n",
    "reference = \"\".join(reference.split(\"\\n\")[1:])\n",
    "print(f\"Reference genome length: {len(reference)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_mapping(mapping, report):\n",
    "    if mapping.is_secondary:\n",
    "        return\n",
    "    r = reference[mapping.reference_start: mapping.reference_end]\n",
    "    q = mapping.seq[mapping.qstart: mapping.qend]\n",
    "    errors_string = \"\"\n",
    "    r_idx = 0\n",
    "    q_idx = 0\n",
    "    for sort, n in mapping.cigar:\n",
    "        if sort == 0:\n",
    "            for _ in range(n):\n",
    "                r_nt = r[r_idx]\n",
    "                q_nt = q[q_idx]\n",
    "                errors_string += \"E\" if r_nt != q_nt else \"C\"\n",
    "                r_idx += 1\n",
    "                q_idx += 1\n",
    "        elif sort == 1:\n",
    "            errors_string += n * \"E\"\n",
    "            q_idx += n\n",
    "        elif sort == 2:\n",
    "            r_idx += n\n",
    "        elif sort == 4 or sort == 5:\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception\n",
    "    key = mapping.qname + (\"_read1\" if mapping.is_read1 else \"_read2\")\n",
    "    report[key] = errors_string, mapping.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оригинальные риды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of ecoli_10K_err_1.fastq\n",
      "Approx 5% complete for ecoli_10K_err_1.fastq\n",
      "Approx 10% complete for ecoli_10K_err_1.fastq\n",
      "Approx 15% complete for ecoli_10K_err_1.fastq\n",
      "Approx 20% complete for ecoli_10K_err_1.fastq\n",
      "Approx 25% complete for ecoli_10K_err_1.fastq\n",
      "Approx 30% complete for ecoli_10K_err_1.fastq\n",
      "Approx 35% complete for ecoli_10K_err_1.fastq\n",
      "Approx 40% complete for ecoli_10K_err_1.fastq\n",
      "Approx 45% complete for ecoli_10K_err_1.fastq\n",
      "Approx 50% complete for ecoli_10K_err_1.fastq\n",
      "Approx 55% complete for ecoli_10K_err_1.fastq\n",
      "Approx 60% complete for ecoli_10K_err_1.fastq\n",
      "Approx 65% complete for ecoli_10K_err_1.fastq\n",
      "Approx 70% complete for ecoli_10K_err_1.fastq\n",
      "Approx 75% complete for ecoli_10K_err_1.fastq\n",
      "Approx 80% complete for ecoli_10K_err_1.fastq\n",
      "Approx 85% complete for ecoli_10K_err_1.fastq\n",
      "Approx 90% complete for ecoli_10K_err_1.fastq\n",
      "Approx 95% complete for ecoli_10K_err_1.fastq\n",
      "Analysis complete for ecoli_10K_err_1.fastq\n",
      "Started analysis of ecoli_10K_err_2.fastq\n",
      "Approx 5% complete for ecoli_10K_err_2.fastq\n",
      "Approx 10% complete for ecoli_10K_err_2.fastq\n",
      "Approx 15% complete for ecoli_10K_err_2.fastq\n",
      "Approx 20% complete for ecoli_10K_err_2.fastq\n",
      "Approx 25% complete for ecoli_10K_err_2.fastq\n",
      "Approx 30% complete for ecoli_10K_err_2.fastq\n",
      "Approx 35% complete for ecoli_10K_err_2.fastq\n",
      "Approx 40% complete for ecoli_10K_err_2.fastq\n",
      "Approx 45% complete for ecoli_10K_err_2.fastq\n",
      "Approx 50% complete for ecoli_10K_err_2.fastq\n",
      "Approx 55% complete for ecoli_10K_err_2.fastq\n",
      "Approx 60% complete for ecoli_10K_err_2.fastq\n",
      "Approx 65% complete for ecoli_10K_err_2.fastq\n",
      "Approx 70% complete for ecoli_10K_err_2.fastq\n",
      "Approx 75% complete for ecoli_10K_err_2.fastq\n",
      "Approx 80% complete for ecoli_10K_err_2.fastq\n",
      "Approx 85% complete for ecoli_10K_err_2.fastq\n",
      "Approx 90% complete for ecoli_10K_err_2.fastq\n",
      "Approx 95% complete for ecoli_10K_err_2.fastq\n",
      "Analysis complete for ecoli_10K_err_2.fastq\n"
     ]
    }
   ],
   "source": [
    "!fastqc -o original ../../data/hw_4/ecoli_10K_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество для оригинальных ридов (FastQC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"original/orig_qual.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index ../../data/hw_4/MG1655-K12.first10K.fasta\n",
      "[main] Real time: 0.013 sec; CPU: 0.013 sec\n"
     ]
    }
   ],
   "source": [
    "!bwa index ../../data/hw_4/MG1655-K12.first10K.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 59278 sequences (5927800 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 29468, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (207, 214, 222)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (177, 252)\n",
      "[M::mem_pestat] mean and std.dev: (214.40, 10.18)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (162, 267)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 59278 reads in 1.308 CPU sec, 1.310 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem ../../data/hw_4/MG1655-K12.first10K.fasta ../../data/hw_4/ecoli_10K_err_1.fastq ../../data/hw_4/ecoli_10K_err_2.fastq\n",
      "[main] Real time: 1.413 sec; CPU: 1.414 sec\n"
     ]
    }
   ],
   "source": [
    "!bwa mem ../../data/hw_4/MG1655-K12.first10K.fasta \\\n",
    "../../data/hw_4/ecoli_10K_err_1.fastq ../../data/hw_4/ecoli_10K_err_2.fastq \\\n",
    "> ../../data/hw_4/alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59278 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "0 + 0 secondary\n",
      "0 + 0 supplementary\n",
      "0 + 0 duplicates\n",
      "59261 + 0 mapped (99.97% : N/A)\n",
      "59278 + 0 paired in sequencing\n",
      "29639 + 0 read1\n",
      "29639 + 0 read2\n",
      "59216 + 0 properly paired (99.90% : N/A)\n",
      "59246 + 0 with itself and mate mapped\n",
      "15 + 0 singletons (0.03% : N/A)\n",
      "0 + 0 with mate mapped to a different chr\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "!samtools flagstat ../../data/hw_4/alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59278/59278 [00:01<00:00, 54765.39it/s]\n"
     ]
    }
   ],
   "source": [
    "original_reads_errors = {}\n",
    "with pysam.AlignmentFile(os.path.join(data_path, \"alignment.sam\")) as f:\n",
    "    for mapping in tqdm(f.fetch(), total=59278):\n",
    "        analyse_mapping(mapping, original_reads_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimmomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticPE: Started with arguments:\n",
      " -phred33 -trimlog ./trimmomatic/trimlog.txt -summary ./trimmomatic/summary.txt ../../data/hw_4/ecoli_10K_err_1.fastq ../../data/hw_4/ecoli_10K_err_2.fastq ../../data/hw_4/trimmomatic/corrected_1P.fq ../../data/hw_4/trimmomatic/corrected_1U.fq ../../data/hw_4/trimmomatic/corrected_2P.fq ../../data/hw_4/trimmomatic/corrected_2U.fq LEADING:20 TRAILING:20 SLIDINGWINDOW:10:20 MINLEN:20\n",
      "Input Read Pairs: 29639 Both Surviving: 28722 (96,91%) Forward Only Surviving: 597 (2,01%) Reverse Only Surviving: 276 (0,93%) Dropped: 44 (0,15%)\n",
      "TrimmomaticPE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "!trimmomatic PE -phred33 -trimlog ./trimmomatic/trimlog.txt -summary ./trimmomatic/summary.txt \\\n",
    "../../data/hw_4/ecoli_10K_err_1.fastq ../../data/hw_4/ecoli_10K_err_2.fastq \\\n",
    "../../data/hw_4/trimmomatic/corrected_1P.fq ../../data/hw_4/trimmomatic/corrected_1U.fq \\\n",
    "../../data/hw_4/trimmomatic/corrected_2P.fq ../../data/hw_4/trimmomatic/corrected_2U.fq \\\n",
    "LEADING:20 TRAILING:20 SLIDINGWINDOW:10:20 MINLEN:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of corrected_1P.fq\n",
      "Approx 5% complete for corrected_1P.fq\n",
      "Approx 10% complete for corrected_1P.fq\n",
      "Approx 15% complete for corrected_1P.fq\n",
      "Approx 20% complete for corrected_1P.fq\n",
      "Approx 25% complete for corrected_1P.fq\n",
      "Approx 30% complete for corrected_1P.fq\n",
      "Approx 35% complete for corrected_1P.fq\n",
      "Approx 40% complete for corrected_1P.fq\n",
      "Approx 45% complete for corrected_1P.fq\n",
      "Approx 50% complete for corrected_1P.fq\n",
      "Approx 55% complete for corrected_1P.fq\n",
      "Approx 60% complete for corrected_1P.fq\n",
      "Approx 65% complete for corrected_1P.fq\n",
      "Approx 70% complete for corrected_1P.fq\n",
      "Approx 75% complete for corrected_1P.fq\n",
      "Approx 80% complete for corrected_1P.fq\n",
      "Approx 85% complete for corrected_1P.fq\n",
      "Approx 90% complete for corrected_1P.fq\n",
      "Approx 95% complete for corrected_1P.fq\n",
      "Analysis complete for corrected_1P.fq\n",
      "Started analysis of corrected_2P.fq\n",
      "Approx 5% complete for corrected_2P.fq\n",
      "Approx 10% complete for corrected_2P.fq\n",
      "Approx 15% complete for corrected_2P.fq\n",
      "Approx 20% complete for corrected_2P.fq\n",
      "Approx 25% complete for corrected_2P.fq\n",
      "Approx 30% complete for corrected_2P.fq\n",
      "Approx 35% complete for corrected_2P.fq\n",
      "Approx 40% complete for corrected_2P.fq\n",
      "Approx 45% complete for corrected_2P.fq\n",
      "Approx 50% complete for corrected_2P.fq\n",
      "Approx 55% complete for corrected_2P.fq\n",
      "Approx 60% complete for corrected_2P.fq\n",
      "Approx 65% complete for corrected_2P.fq\n",
      "Approx 70% complete for corrected_2P.fq\n",
      "Approx 75% complete for corrected_2P.fq\n",
      "Approx 80% complete for corrected_2P.fq\n",
      "Approx 85% complete for corrected_2P.fq\n",
      "Approx 90% complete for corrected_2P.fq\n",
      "Approx 95% complete for corrected_2P.fq\n",
      "Analysis complete for corrected_2P.fq\n"
     ]
    }
   ],
   "source": [
    "!fastqc -o trimmomatic ../../data/hw_4/trimmomatic/corrected_1P.fq ../../data/hw_4/trimmomatic/corrected_2P.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество для ридов, обработанных Trimmomatic (FastQC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"trimmomatic/trim_qual.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 57444 sequences (5119460 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 28434, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (207, 214, 222)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (177, 252)\n",
      "[M::mem_pestat] mean and std.dev: (214.38, 10.19)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (162, 267)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 57444 reads in 0.937 CPU sec, 0.938 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem ../../data/hw_4/MG1655-K12.first10K.fasta ../../data/hw_4/trimmomatic/corrected_1P.fq ../../data/hw_4/trimmomatic/corrected_2P.fq\n",
      "[main] Real time: 1.047 sec; CPU: 1.049 sec\n"
     ]
    }
   ],
   "source": [
    "!bwa mem ../../data/hw_4/MG1655-K12.first10K.fasta \\\n",
    "../../data/hw_4/trimmomatic/corrected_1P.fq ../../data/hw_4/trimmomatic/corrected_2P.fq \\\n",
    "> ../../data/hw_4/trimmomatic/alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57444 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "0 + 0 secondary\n",
      "0 + 0 supplementary\n",
      "0 + 0 duplicates\n",
      "57419 + 0 mapped (99.96% : N/A)\n",
      "57444 + 0 paired in sequencing\n",
      "28722 + 0 read1\n",
      "28722 + 0 read2\n",
      "57364 + 0 properly paired (99.86% : N/A)\n",
      "57394 + 0 with itself and mate mapped\n",
      "25 + 0 singletons (0.04% : N/A)\n",
      "0 + 0 with mate mapped to a different chr\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "!samtools flagstat ../../data/hw_4/trimmomatic/alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57444/57444 [00:00<00:00, 57778.19it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected_reads_errors = {}\n",
    "with pysam.AlignmentFile(os.path.join(data_path, \"trimmomatic\", \"alignment.sam\")) as f:\n",
    "    for mapping in tqdm(f.fetch(), total=57444):\n",
    "        analyse_mapping(mapping, corrected_reads_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_matrix = pd.DataFrame(\n",
    "    index=[\"Error (Original)\", \"Correct (Original)\"],\n",
    "    columns=[\"Error (Corrected)\", \"Correct (Corrected)\", \"Absence (Corrected)\"],\n",
    "    data=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59278/59278 [16:41<00:00, 59.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for qname, (orig_seq, orig_pos) in tqdm(original_reads_errors.items()):\n",
    "    try: # проверяем сохранилась ли пара прочтений после коррекции\n",
    "        corr_seq, corr_pos = corrected_reads_errors[qname]\n",
    "    except KeyError:\n",
    "        continue\n",
    "    # дописываем плейсхолдеры в начало и конец обрезанных ридов\n",
    "    if orig_pos != corr_pos:\n",
    "        corr_seq = abs(orig_pos-corr_pos) * \"A\" + corr_seq\n",
    "    if len(orig_seq) > len(corr_seq):\n",
    "        corr_seq += abs(len(orig_seq) - len(corr_seq)) * \"A\"\n",
    "    elif len(orig_seq) < len(corr_seq): # так как при выравнивании оригинальный рид тоже обрезается (softclipping), \\\n",
    "                                        # случается так, что он оказывается короче скорректированного рида\n",
    "        orig_seq += abs(len(orig_seq) - len(corr_seq)) * \"A\"\n",
    "    assert len(orig_seq) == len(corr_seq)\n",
    "    for orig_nt, corr_nt in zip(list(orig_seq), list(corr_seq)):\n",
    "        if orig_nt == \"C\" and corr_nt == \"E\":\n",
    "            correction_matrix.loc[\"Correct (Original)\", \"Error (Corrected)\"] += 1\n",
    "        elif orig_nt == \"C\" and corr_nt == \"C\":\n",
    "            correction_matrix.loc[\"Correct (Original)\", \"Correct (Corrected)\"] += 1\n",
    "        elif orig_nt == \"C\" and corr_nt == \"A\":\n",
    "            correction_matrix.loc[\"Correct (Original)\", \"Absence (Corrected)\"] += 1\n",
    "        elif orig_nt == \"E\" and corr_nt == \"E\":\n",
    "            correction_matrix.loc[\"Error (Original)\", \"Error (Corrected)\"] += 1\n",
    "        elif orig_nt == \"E\" and corr_nt == \"C\":\n",
    "            correction_matrix.loc[\"Error (Original)\", \"Correct (Corrected)\"] += 1\n",
    "        elif orig_nt == \"E\" and corr_nt == \"A\":\n",
    "            correction_matrix.loc[\"Error (Original)\", \"Absence (Corrected)\"] += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error (Corrected)</th>\n",
       "      <th>Correct (Corrected)</th>\n",
       "      <th>Absence (Corrected)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Error (Original)</td>\n",
       "      <td>17848</td>\n",
       "      <td>135</td>\n",
       "      <td>32592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Correct (Original)</td>\n",
       "      <td>374</td>\n",
       "      <td>5095858</td>\n",
       "      <td>421162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Error (Corrected)  Correct (Corrected)  \\\n",
       "Error (Original)                17848                  135   \n",
       "Correct (Original)                374              5095858   \n",
       "\n",
       "                    Absence (Corrected)  \n",
       "Error (Original)                  32592  \n",
       "Correct (Original)               421162  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesHammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "== Warning ==  output dir is not empty! Please, clean output directory before run.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Warning ==  No assembly mode was specified! If you intend to assemble high-coverage multi-cell/isolate data, use '--isolate' option.\n",
      "\n",
      "\n",
      "Command line: ../../../../bin/SPAdes-3.14.1-Darwin/bin/spades.py\t--only-error-correction\t-1\t/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_1.fastq\t-2\t/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_2.fastq\t-o\t/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer\t\n",
      "\n",
      "System information:\n",
      "  SPAdes version: 3.14.1\n",
      "  Python version: 3.7.4\n",
      "  OS: Darwin-19.6.0-x86_64-i386-64bit\n",
      "\n",
      "Output dir: /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer\n",
      "Mode: ONLY read error correction (without assembling)\n",
      "Debug mode is turned OFF\n",
      "\n",
      "Dataset parameters:\n",
      "  Standard mode\n",
      "  For multi-cell/isolate data we recommend to use '--isolate' option; for single-cell MDA data use '--sc'; for metagenomic data use '--meta'; for RNA-Seq use '--rna'.\n",
      "  Reads:\n",
      "    Library number: 1, library type: paired-end\n",
      "      orientation: fr\n",
      "      left reads: ['/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_1.fastq']\n",
      "      right reads: ['/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_2.fastq']\n",
      "      interlaced reads: not specified\n",
      "      single reads: not specified\n",
      "      merged reads: not specified\n",
      "Read error correction parameters:\n",
      "  Iterations: 1\n",
      "  PHRED offset will be auto-detected\n",
      "  Corrected reads will be compressed\n",
      "Other parameters:\n",
      "  Dir for temp files: /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/tmp\n",
      "  Threads: 16\n",
      "  Memory limit (in Gb): 250\n",
      "\n",
      "\n",
      "======= SPAdes pipeline started. Log can be found here: /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/spades.log\n",
      "\n",
      "\n",
      "===== Before start started. \n",
      "\n",
      "\n",
      "===== Read error correction started. \n",
      "\n",
      "\n",
      "===== Read error correction started. \n",
      "\n",
      "\n",
      "== Running: /Users/a18264698/Desktop/BIOINF/bin/SPAdes-3.14.1-Darwin/bin/spades-hammer /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/configs/config.info\n",
      "\n",
      "  0:00:00.000     4M / 4M    INFO    General                 (main.cpp                  :  75)   Starting BayesHammer, built from N/A, git revision N/A\n",
      "  0:00:00.000     4M / 4M    INFO    General                 (main.cpp                  :  76)   Loading config from /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/configs/config.info\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (main.cpp                  :  78)   Maximum # of threads to use (adjusted due to OMP capabilities): 12\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (memory_limit.cpp          :  49)   Memory limit set to 250 Gb\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (main.cpp                  :  86)   Trying to determine PHRED offset\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (main.cpp                  :  92)   Determined value is 33\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (hammer_tools.cpp          :  38)   Hamming graph threshold tau=1, k=21, subkmer positions = [ 0 10 ]\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (main.cpp                  : 113)   Size of aux. kmer data 24 bytes\n",
      "     === ITERATION 0 begins ===\n",
      "  0:00:00.005     4M / 4M    INFO   K-mer Index Building     (kmer_index_builder.hpp    : 301)   Building kmer index\n",
      "  0:00:00.005     4M / 4M    INFO    General                 (kmer_index_builder.hpp    : 117)   Splitting kmer instances into 192 files using 12 threads. This might take a while.\n",
      "  0:00:00.006     4M / 4M    INFO    General                 (file_limit.hpp            :  32)   Open file limit set to 256\n",
      "  0:00:00.006     4M / 4M    INFO    General                 (kmer_splitters.hpp        :  89)   Memory available for splitting buffers: 6.94443 Gb\n",
      "  0:00:00.006     4M / 4M    INFO    General                 (kmer_splitters.hpp        :  97)   Using cell size of 349525\n",
      "  0:00:00.009     5M / 5M    INFO   K-mer Splitting          (kmer_data.cpp             :  97)   Processing /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_1.fastq\n",
      "  0:00:00.177     6M / 44M   INFO   K-mer Splitting          (kmer_data.cpp             :  97)   Processing /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_2.fastq\n",
      "  0:00:00.298     6M / 45M   INFO   K-mer Splitting          (kmer_data.cpp             : 107)   Processed 59278 reads\n",
      "  0:00:00.298     6M / 45M   INFO   K-mer Splitting          (kmer_data.cpp             : 112)   Total 59278 reads processed\n",
      "  0:00:00.341     6M / 6M    INFO    General                 (kmer_index_builder.hpp    : 120)   Starting k-mer counting.\n",
      "  0:00:00.522     6M / 6M    INFO    General                 (kmer_index_builder.hpp    : 127)   K-mer counting done. There are 318944 kmers in total.\n",
      "  0:00:00.522     6M / 6M    INFO    General                 (kmer_index_builder.hpp    : 133)   Merging temporary buckets.\n",
      "  0:00:00.679     6M / 6M    INFO   K-mer Index Building     (kmer_index_builder.hpp    : 314)   Building perfect hash indices\n",
      "  0:00:00.716     9M / 9M    INFO    General                 (kmer_index_builder.hpp    : 150)   Merging final buckets.\n",
      "  0:00:00.720     9M / 9M    INFO   K-mer Index Building     (kmer_index_builder.hpp    : 336)   Index built. Total 156336 bytes occupied (3.92134 bits per kmer).\n",
      "  0:00:00.720     9M / 9M    INFO   K-mer Counting           (kmer_data.cpp             : 351)   Arranging kmers in hash map order\n",
      "  0:00:00.931    14M / 14M   INFO    General                 (main.cpp                  : 148)   Clustering Hamming graph.\n",
      "  0:00:01.043    14M / 14M   INFO    General                 (main.cpp                  : 155)   Extracting clusters\n",
      "  0:00:01.065    18M / 18M   INFO    General                 (main.cpp                  : 167)   Clustering done. Total clusters: 55766\n",
      "  0:00:01.065    18M / 18M   INFO   K-mer Counting           (kmer_data.cpp             : 371)   Collecting K-mer information, this takes a while.\n",
      "  0:00:01.068    26M / 26M   INFO   K-mer Counting           (kmer_data.cpp             : 377)   Processing /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_1.fastq\n",
      "  0:00:01.204    26M / 26M   INFO   K-mer Counting           (kmer_data.cpp             : 377)   Processing /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_2.fastq\n",
      "  0:00:01.345    26M / 26M   INFO   K-mer Counting           (kmer_data.cpp             : 384)   Collection done, postprocessing.\n",
      "  0:00:01.347    26M / 26M   INFO   K-mer Counting           (kmer_data.cpp             : 397)   There are 318944 kmers in total. Among them 235964 (73.9829%) are singletons.\n",
      "  0:00:01.347    26M / 26M   INFO    General                 (main.cpp                  : 173)   Subclustering Hamming graph\n",
      "  0:00:01.388    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 649)   Subclustering done. Total 0 non-read kmers were generated.\n",
      "  0:00:01.389    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 650)   Subclustering statistics:\n",
      "  0:00:01.389    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 651)     Total singleton hamming clusters: 35666. Among them 64 (0.179443%) are good\n",
      "  0:00:01.389    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 652)     Total singleton subclusters: 120. Among them 120 (100%) are good\n",
      "  0:00:01.390    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 653)     Total non-singleton subcluster centers: 21147. Among them 20696 (97.8673%) are good\n",
      "  0:00:01.390    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 654)     Average size of non-trivial subcluster: 13.3957 kmers\n",
      "  0:00:01.390    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 655)     Average number of sub-clusters per non-singleton cluster: 1.05806\n",
      "  0:00:01.390    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 656)     Total solid k-mers: 20880\n",
      "  0:00:01.391    30M / 30M   INFO   Hamming Subclustering    (kmer_cluster.cpp          : 657)     Substitution probabilities: [4,4]((0.925229,0.0425029,0.0243006,0.00796784),(0.0159228,0.960759,0.0124884,0.0108302),(0.0108104,0.0124639,0.960776,0.0159498),(0.00795598,0.0242883,0.0424732,0.925282))\n",
      "  0:00:01.391    30M / 30M   INFO    General                 (main.cpp                  : 178)   Finished clustering.\n",
      "  0:00:01.391    30M / 30M   INFO    General                 (main.cpp                  : 197)   Starting solid k-mers expansion in 12 threads.\n",
      "  0:00:01.468    30M / 30M   INFO    General                 (main.cpp                  : 218)   Solid k-mers iteration 0 produced 717 new k-mers.\n",
      "  0:00:01.546    30M / 30M   INFO    General                 (main.cpp                  : 218)   Solid k-mers iteration 1 produced 13 new k-mers.\n",
      "  0:00:01.624    30M / 30M   INFO    General                 (main.cpp                  : 218)   Solid k-mers iteration 2 produced 0 new k-mers.\n",
      "  0:00:01.625    30M / 30M   INFO    General                 (main.cpp                  : 222)   Solid k-mers finalized\n",
      "  0:00:01.625    30M / 30M   INFO    General                 (hammer_tools.cpp          : 222)   Starting read correction in 12 threads.\n",
      "  0:00:01.625    30M / 30M   INFO    General                 (hammer_tools.cpp          : 235)   Correcting pair of reads: /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_1.fastq and /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/ecoli_10K_err_2.fastq\n",
      "  0:00:01.792   363M / 363M  INFO    General                 (hammer_tools.cpp          : 170)   Prepared batch 0 of 29639 reads.\n",
      "  0:00:01.871   363M / 363M  INFO    General                 (hammer_tools.cpp          : 177)   Processed batch 0\n",
      "  0:00:01.974   363M / 363M  INFO    General                 (hammer_tools.cpp          : 187)   Written batch 0\n",
      "  0:00:02.019    43M / 43M   INFO    General                 (hammer_tools.cpp          : 276)   Correction done. Changed 19891 bases in 14429 reads.\n",
      "  0:00:02.019    43M / 43M   INFO    General                 (hammer_tools.cpp          : 277)   Failed to correct 565 bases out of 5305818.\n",
      "  0:00:02.020    27M / 27M   INFO    General                 (main.cpp                  : 255)   Saving corrected dataset description to /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/corrected.yaml\n",
      "  0:00:02.021    27M / 27M   INFO    General                 (main.cpp                  : 262)   All done. Exiting.\n",
      "\n",
      "===== Read error correction finished. \n",
      "\n",
      "\n",
      "===== corrected reads compression started. \n",
      "\n",
      "\n",
      "== Running: /opt/anaconda3/bin/python /Users/a18264698/Desktop/BIOINF/bin/SPAdes-3.14.1-Darwin/share/spades/spades_pipeline/scripts/compress_all.py --input_file /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/corrected.yaml --ext_python_modules_home /Users/a18264698/Desktop/BIOINF/bin/SPAdes-3.14.1-Darwin/share/spades --max_threads 16 --output_dir /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected --gzip_output\n",
      "\n",
      "== Compressing corrected reads (with gzip)\n",
      "== Files to compress: ['/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/ecoli_10K_err_1.00.0_0.cor.fastq', '/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/ecoli_10K_err_2.00.0_0.cor.fastq', '/Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/ecoli_10K_err__unpaired.00.0_0.cor.fastq']\n",
      "== Files compression is finished\n",
      "== Dataset yaml file is updated\n",
      "\n",
      "===== corrected reads compression finished. \n",
      "\n",
      "\n",
      "===== Read error correction finished. \n",
      "\n",
      "\n",
      "===== Breaking scaffolds started. \n",
      "\n",
      "\n",
      "== Running: /opt/anaconda3/bin/python /Users/a18264698/Desktop/BIOINF/bin/SPAdes-3.14.1-Darwin/share/spades/spades_pipeline/scripts/breaking_scaffolds_script.py --result_scaffolds_filename /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/scaffolds.fasta --misc_dir /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/misc --threshold_for_breaking_scaffolds 3\n",
      "\n",
      "\n",
      "===== Breaking scaffolds finished. \n",
      "\n",
      "\n",
      "===== Terminate started. \n",
      "\n",
      "\n",
      "===== Terminate finished. \n",
      "\n",
      " * Corrected reads are in /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/corrected/\n",
      "\n",
      "======= SPAdes pipeline finished.\n",
      "\n",
      "SPAdes log can be found here: /Users/a18264698/Desktop/BIOINF/2_semester/NGS/data/hw_4/bayeshammer/spades.log\n",
      "\n",
      "Thank you for using SPAdes!\n"
     ]
    }
   ],
   "source": [
    "!../../../../bin/SPAdes-3.14.1-Darwin/bin/spades.py --only-error-correction\\\n",
    "-1 ../../data/hw_4/ecoli_10K_err_1.fastq -2 ../../data/hw_4/ecoli_10K_err_2.fastq \\\n",
    "-o ../../data/hw_4/bayeshammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -dc ../../data/hw_4/bayeshammer/corrected/ecoli_10K_err_1.00.0_0.cor.fastq.gz \\\n",
    "> ../../data/hw_4/bayeshammer/corrected_1P.fq\n",
    "!gzip -dc ../../data/hw_4/bayeshammer/corrected/ecoli_10K_err_2.00.0_0.cor.fastq.gz \\\n",
    "> ../../data/hw_4/bayeshammer/corrected_2P.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of corrected_1P.fq\n",
      "Approx 5% complete for corrected_1P.fq\n",
      "Approx 10% complete for corrected_1P.fq\n",
      "Approx 15% complete for corrected_1P.fq\n",
      "Approx 20% complete for corrected_1P.fq\n",
      "Approx 25% complete for corrected_1P.fq\n",
      "Approx 30% complete for corrected_1P.fq\n",
      "Approx 35% complete for corrected_1P.fq\n",
      "Approx 40% complete for corrected_1P.fq\n",
      "Approx 45% complete for corrected_1P.fq\n",
      "Approx 50% complete for corrected_1P.fq\n",
      "Approx 55% complete for corrected_1P.fq\n",
      "Approx 60% complete for corrected_1P.fq\n",
      "Approx 65% complete for corrected_1P.fq\n",
      "Approx 70% complete for corrected_1P.fq\n",
      "Approx 75% complete for corrected_1P.fq\n",
      "Approx 80% complete for corrected_1P.fq\n",
      "Approx 85% complete for corrected_1P.fq\n",
      "Approx 90% complete for corrected_1P.fq\n",
      "Approx 95% complete for corrected_1P.fq\n",
      "Analysis complete for corrected_1P.fq\n",
      "Started analysis of corrected_2P.fq\n",
      "Approx 5% complete for corrected_2P.fq\n",
      "Approx 10% complete for corrected_2P.fq\n",
      "Approx 15% complete for corrected_2P.fq\n",
      "Approx 20% complete for corrected_2P.fq\n",
      "Approx 25% complete for corrected_2P.fq\n",
      "Approx 30% complete for corrected_2P.fq\n",
      "Approx 35% complete for corrected_2P.fq\n",
      "Approx 40% complete for corrected_2P.fq\n",
      "Approx 45% complete for corrected_2P.fq\n",
      "Approx 50% complete for corrected_2P.fq\n",
      "Approx 55% complete for corrected_2P.fq\n",
      "Approx 60% complete for corrected_2P.fq\n",
      "Approx 65% complete for corrected_2P.fq\n",
      "Approx 70% complete for corrected_2P.fq\n",
      "Approx 75% complete for corrected_2P.fq\n",
      "Approx 80% complete for corrected_2P.fq\n",
      "Approx 85% complete for corrected_2P.fq\n",
      "Approx 90% complete for corrected_2P.fq\n",
      "Approx 95% complete for corrected_2P.fq\n",
      "Analysis complete for corrected_2P.fq\n"
     ]
    }
   ],
   "source": [
    "!fastqc -o bayeshammer ../../data/hw_4/bayeshammer/corrected_1P.fq ../../data/hw_4/bayeshammer/corrected_2P.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество для ридов, обработанных BayesHammer (FastQC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bayeshammer/bayes_qual.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 57986 sequences (5798600 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 28895, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (207, 214, 222)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (177, 252)\n",
      "[M::mem_pestat] mean and std.dev: (214.39, 10.18)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (162, 267)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 57986 reads in 0.887 CPU sec, 0.887 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem ../../data/hw_4/MG1655-K12.first10K.fasta ../../data/hw_4/bayeshammer/corrected_1P.fq ../../data/hw_4/bayeshammer/corrected_2P.fq\n",
      "[main] Real time: 1.020 sec; CPU: 1.010 sec\n"
     ]
    }
   ],
   "source": [
    "!bwa mem ../../data/hw_4/MG1655-K12.first10K.fasta \\\n",
    "../../data/hw_4/bayeshammer/corrected_1P.fq ../../data/hw_4/bayeshammer/corrected_2P.fq \\\n",
    "> ../../data/hw_4/bayeshammer/alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57986 + 0 in total (QC-passed reads + QC-failed reads)\n",
      "0 + 0 secondary\n",
      "0 + 0 supplementary\n",
      "0 + 0 duplicates\n",
      "57984 + 0 mapped (100.00% : N/A)\n",
      "57986 + 0 paired in sequencing\n",
      "28993 + 0 read1\n",
      "28993 + 0 read2\n",
      "57952 + 0 properly paired (99.94% : N/A)\n",
      "57982 + 0 with itself and mate mapped\n",
      "2 + 0 singletons (0.00% : N/A)\n",
      "0 + 0 with mate mapped to a different chr\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
     ]
    }
   ],
   "source": [
    "!samtools flagstat ../../data/hw_4/bayeshammer/alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57986/57986 [00:01<00:00, 57980.10it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected_reads_errors = {}\n",
    "with pysam.AlignmentFile(os.path.join(data_path, \"bayeshammer\", \"alignment.sam\")) as f:\n",
    "    for mapping in tqdm(f.fetch(), total=57986):\n",
    "        analyse_mapping(mapping, corrected_reads_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_matrix = pd.DataFrame(\n",
    "    index=[\"Error (Original)\", \"Correct (Original)\"],\n",
    "    columns=[\"Error (Corrected)\", \"Correct (Corrected)\", \"Absence (Corrected)\"],\n",
    "    data=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59278/59278 [16:36<00:00, 59.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for qname, (orig_seq, orig_pos) in tqdm(original_reads_errors.items()):\n",
    "    try: # проверяем сохранилась ли пара прочтений после коррекции\n",
    "        corr_seq, corr_pos = corrected_reads_errors[qname]\n",
    "    except KeyError:\n",
    "        continue\n",
    "    # дописываем плейсхолдеры в начало и конец обрезанных ридов\n",
    "    if orig_pos != corr_pos:\n",
    "        corr_seq = abs(orig_pos-corr_pos) * \"A\" + corr_seq\n",
    "    if len(orig_seq) > len(corr_seq):\n",
    "        corr_seq += abs(len(orig_seq) - len(corr_seq)) * \"A\"\n",
    "    elif len(orig_seq) < len(corr_seq): # так как при выравнивании оригинальный рид тоже обрезается (softclipping), \\\n",
    "                                        # случается так, что он оказывается короче скорректированного рида\n",
    "        orig_seq += abs(len(orig_seq) - len(corr_seq)) * \"A\"\n",
    "    assert len(orig_seq) == len(corr_seq)\n",
    "    for orig_nt, corr_nt in zip(list(orig_seq), list(corr_seq)):\n",
    "        if orig_nt == \"C\" and corr_nt == \"E\":\n",
    "            correction_matrix.loc[\"Correct (Original)\", \"Error (Corrected)\"] += 1\n",
    "        elif orig_nt == \"C\" and corr_nt == \"C\":\n",
    "            correction_matrix.loc[\"Correct (Original)\", \"Correct (Corrected)\"] += 1\n",
    "        elif orig_nt == \"C\" and corr_nt == \"A\":\n",
    "            correction_matrix.loc[\"Correct (Original)\", \"Absence (Corrected)\"] += 1\n",
    "        elif orig_nt == \"E\" and corr_nt == \"E\":\n",
    "            correction_matrix.loc[\"Error (Original)\", \"Error (Corrected)\"] += 1\n",
    "        elif orig_nt == \"E\" and corr_nt == \"C\":\n",
    "            correction_matrix.loc[\"Error (Original)\", \"Correct (Corrected)\"] += 1\n",
    "        elif orig_nt == \"E\" and corr_nt == \"A\":\n",
    "            correction_matrix.loc[\"Error (Original)\", \"Absence (Corrected)\"] += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error (Corrected)</th>\n",
       "      <th>Correct (Corrected)</th>\n",
       "      <th>Absence (Corrected)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Error (Original)</td>\n",
       "      <td>3575</td>\n",
       "      <td>18837</td>\n",
       "      <td>29158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Correct (Original)</td>\n",
       "      <td>8341</td>\n",
       "      <td>5220792</td>\n",
       "      <td>340750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Error (Corrected)  Correct (Corrected)  \\\n",
       "Error (Original)                 3575                18837   \n",
       "Correct (Original)               8341              5220792   \n",
       "\n",
       "                    Absence (Corrected)  \n",
       "Error (Original)                  29158  \n",
       "Correct (Original)               340750  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
